{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/data/train.csv\")"
      ],
      "metadata": {
        "id": "sdLRPlRP_f7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "i8kh5Hu6CCw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available and being used\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "if gpu_available:\n",
        "  print(\"GPU is available:\", gpu_available)\n",
        "else:\n",
        "  print(\"GPU is not available. Make sure you have selected a GPU runtime.\")"
      ],
      "metadata": {
        "id": "T3QATk1UlMTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seals_price_high_correlation_features = [\"SalePrice\",\"1stFlrSF\", \"GarageArea\", \"GarageYrBlt\", \"GrLivArea\", \"OverallQual\", \"TotRmsAbvGrd\", \"TotalBsmtSF\" , \"YearBuilt\", \"YearRemodAdd\"]\n",
        "\n",
        "\n",
        "df = pd.DataFrame(df[seals_price_high_correlation_features] , columns=seals_price_high_correlation_features)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "qIPwaMloE_S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"GarageYrBlt\"].fillna(df.GarageYrBlt.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "eh70QDzpeIas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FSMIamKAeMBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for model training and evaluation\n",
        "import xgboost as xgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd # Ensure pandas is imported here as it's used for X and y\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop([\"SalePrice\"] , axis=1)\n",
        "y = df[\"SalePrice\"]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# Create a pipeline with StandardScaler and XGBRegressor\n",
        "xgb_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"xgb_model\" , xgb.XGBRegressor(random_state=123)) # Added random_state for reproducibility\n",
        "])\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "xgb_params_grid = {\n",
        "    \"xgb_model__subsample\" : np.arange(0.05, 1, 0.05),\n",
        "    \"xgb_model__max_depth\" : np.arange(3, 20, 1),\n",
        "    \"xgb_model__colsample_bytree\": np.arange(0.1, 1.05, 0.05)\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "xgb_randomCV = RandomizedSearchCV(\n",
        "    estimator=xgb_pipeline,\n",
        "    param_distributions=xgb_params_grid,\n",
        "    n_iter=25, # Number of parameter settings that are sampled\n",
        "    cv=5,       # Number of cross-validation folds\n",
        "    scoring=\"neg_mean_squared_error\", # Scoring metric\n",
        "    verbose=1,  # Controls the verbosity: higher means more messages\n",
        "    random_state=123 # Added random_state for reproducibility\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "xgb_randomCV.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found by RandomizedSearchCV:\")\n",
        "print(xgb_randomCV.best_params_)\n",
        "\n",
        "# Print the best cross-validation score\n",
        "print(\"Best cross-validation score (negative MSE):\")\n",
        "print(xgb_randomCV.best_score_)"
      ],
      "metadata": {
        "id": "r7AIBdUEfKgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgb_randomCV.best_params_)"
      ],
      "metadata": {
        "id": "5QR8Te0nmXUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgb_randomCV.best_score_)"
      ],
      "metadata": {
        "id": "lMbVxctxmiWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Load the test data\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# Define the features to use for prediction.\n",
        "# It's crucial that these match the features used during training (X_train).\n",
        "features_for_prediction = X_train.columns.tolist()\n",
        "\n",
        "# Select and reorder the features in the test data to match the training data\n",
        "# This helps prevent feature mismatch errors during prediction.\n",
        "df_test_features = df_test[features_for_prediction]\n",
        "\n",
        "# Fill missing values in 'GarageYrBlt' in the test set.\n",
        "# In a real-world scenario, you should use the mean from the *training* data\n",
        "# to fill missing values in the test data for consistency.\n",
        "# Here, for simplicity and to match the previous code's approach,\n",
        "# we use the mean of the test set's 'GarageYrBlt'.\n",
        "df_test_features[\"GarageYrBlt\"].fillna(df_test_features[\"GarageYrBlt\"].mean(), inplace=True)\n",
        "\n",
        "# The final test data prepared for prediction\n",
        "X_final_test = df_test_features\n",
        "\n",
        "# Use the best estimator found by RandomizedSearchCV to make predictions on the test set\n",
        "# This ensures the data is scaled and the prediction is made using the best model.\n",
        "y_pred_final = xgb_randomCV.best_estimator_.predict(X_final_test)\n",
        "\n",
        "# Load the sample submission file to get the required format\n",
        "submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "# Replace the 'SalePrice' column in the submission file with the predictions\n",
        "submission['SalePrice'] = y_pred_final\n",
        "\n",
        "# Save the submission file in the specified format\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ],
      "metadata": {
        "id": "hqn-vFVmmmFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
